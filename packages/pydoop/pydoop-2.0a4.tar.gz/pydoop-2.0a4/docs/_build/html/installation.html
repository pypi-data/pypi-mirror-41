
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Installation &#8212; Pydoop 2.0a4 documentation</title>
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Pydoop Script User Guide" href="pydoop_script.html" />
    <link rel="prev" title="Writing Full-Featured Applications" href="tutorial/mapred_api.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pydoop_script.html" title="Pydoop Script User Guide"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial/mapred_api.html" title="Writing Full-Featured Applications"
             accesskey="P">previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="#">Download & Install</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop/issues">Support</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop">Git Repo</a>|&nbsp;</li>
	<li><a href="https://crs4.github.io/pydoop/_pydoop1">Pydoop 1</a></li>
 
      </ul>
    </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.png" alt="Logo"/>
            </a></p>
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Installation</a><ul>
<li><a class="reference internal" href="#supported-platforms">Supported Platforms</a></li>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#environment-setup">Environment Setup</a></li>
<li><a class="reference internal" href="#building-and-installing">Building and Installing</a></li>
<li><a class="reference internal" href="#troubleshooting">Troubleshooting</a></li>
<li><a class="reference internal" href="#testing-your-installation">Testing your Installation</a></li>
<li><a class="reference internal" href="#using-pydoop-on-amazon-emr">Using Pydoop on Amazon EMR</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="tutorial/mapred_api.html"
                                  title="previous chapter">Writing Full-Featured Applications</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="pydoop_script.html"
                                  title="next chapter">Pydoop Script User Guide</a></p>

					<h4>Get Pydoop</h4>
					<ul>
						<li> <a href="https://pypi.python.org/pypi/pydoop">Download page</a> </li>
						<li> <a href="#"> Installation Instructions </a> </li>
					</ul>

					<h4>Contributors</h4>
					<p class="topless">
					Pydoop is developed by:
					<a href="http://www.crs4.it">
						<img src="_static/crs4.png" alt="CRS4" width="200" height="60" />
					</a>
					</p>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="installation">
<span id="id1"></span><h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<p>The fastest way to try Pydoop is via the <a class="reference external" href="https://www.docker.com/">Docker</a>
image:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>docker pull crs4/pydoop
export PORT_FW=&quot;-p 8020:8020 -p 8042:8042 -p 8088:8088 -p 9000:9000 -p 10020:10020 -p 19888:19888 -p 9866:9866 -p 9867:9867 -p 9870:9870 -p 9864:9864 -p 9868:9868&quot;
docker run ${PORT_FW} --name pydoop -d crs4/pydoop
</pre></div>
</div>
<p>This spins up a single-node, <a class="reference external" href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation">pseudo-distributed</a>
Hadoop cluster with <a class="reference external" href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Introduction">HDFS</a>,
<a class="reference external" href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN</a>
and a Job History server. To check that all daemons are up and running, you
can run <code class="docutils literal notranslate"><span class="pre">jps</span></code> on the container. If everything is OK, you should get something
like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker exec -it pydoop bash -c &#39;jps | grep -v Jps&#39;
161 DataNode
356 NodeManager
523 JobHistoryServer
75 NameNode
301 ResourceManager
</pre></div>
</div>
<p>Read on for detailed installation instructions.</p>
<div class="section" id="supported-platforms">
<h2>Supported Platforms<a class="headerlink" href="#supported-platforms" title="Permalink to this headline">¶</a></h2>
<p>At the moment, Pydoop is being tested on <a class="reference external" href="http://www.centos.org">CentOS</a> 7
only, although it should also work on other Linux distros and (possibly with
some tweaking) on macOS. Windows is <strong>not</strong> supported.</p>
</div>
<div class="section" id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="http://www.python.org">Python</a> 2 or 3 (tested with 2.7 and 3.6),
including header files (e.g., <code class="docutils literal notranslate"><span class="pre">python-devel</span></code> on CentOS, <code class="docutils literal notranslate"><span class="pre">python-dev</span></code> on
Debian);</li>
<li><a class="reference external" href="https://pypi.python.org/pypi/setuptools">setuptools</a> &gt;= 3.3;</li>
<li>Hadoop &gt;=2. We currently run regular CI tests with the latest versions of
<a class="reference external" href="http://hadoop.apache.org/releases.html">Apache Hadoop</a> 2.x and 3.x,
but we expect Pydoop to also work on other Hadoop distributions. In
particular, we have tested it on <a class="reference external" href="https://aws.amazon.com/emr">Amazon EMR</a>
(see <a class="reference internal" href="#emr"><span class="std std-ref">Using Pydoop on Amazon EMR</span></a>).</li>
</ul>
<p>These are both build time and run time requirements. At build time only, you
will also need a C++ compiler (e.g., <code class="docutils literal notranslate"><span class="pre">yum</span> <span class="pre">install</span> <span class="pre">gcc</span> <span class="pre">gcc-c++</span></code>) and a JDK
(i.e., a JRE alone is not sufficient) for Pydoop’s extension modules.</p>
<p><strong>Optional:</strong></p>
<ul class="simple">
<li><a class="reference external" href="https://avro.apache.org/">Avro</a> Python implementation to enable
<a class="reference internal" href="examples/avro.html#avro-io"><span class="std std-ref">Avro I/O</span></a> (run time only). Note that the pip packages for Python 2 and 3
are named differently (respectively <code class="docutils literal notranslate"><span class="pre">avro</span></code> and <code class="docutils literal notranslate"><span class="pre">avro-python3</span></code>).</li>
<li>Some examples have additional requirements. Check out the Dockerfile and
<code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> for details.</li>
</ul>
</div>
<div class="section" id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Permalink to this headline">¶</a></h2>
<p>Pydoop needs to know where the JDK and Hadoop are installed on your
system. Although it will try to guess both locations, you can help by
exporting, respectively, the <code class="docutils literal notranslate"><span class="pre">JAVA_HOME</span></code> and <code class="docutils literal notranslate"><span class="pre">HADOOP_HOME</span></code> environment
variables. For instance:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">HADOOP_HOME</span><span class="o">=</span><span class="s2">&quot;/opt/hadoop-3.0.1&quot;</span>
<span class="n">export</span> <span class="n">JAVA_HOME</span><span class="o">=</span><span class="s2">&quot;/usr/lib/jvm/java-8-openjdk-amd64&quot;</span>
</pre></div>
</div>
<p>Note that Pydoop is interested in the <strong>JDK</strong> home (where <code class="docutils literal notranslate"><span class="pre">include/jni.h</span></code>
can be found), not the JRE home. Depending on your Java distribution and
version, these can be different directories (usually the former being the
latter’s parent).</p>
</div>
<div class="section" id="building-and-installing">
<h2>Building and Installing<a class="headerlink" href="#building-and-installing" title="Permalink to this headline">¶</a></h2>
<p>Install prerequisites:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">pip</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<p>Install Pydoop via pip:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pydoop</span>
</pre></div>
</div>
<p>Or get the source code and build it locally:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="o">-</span><span class="n">b</span> <span class="n">master</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">crs4</span><span class="o">/</span><span class="n">pydoop</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">pydoop</span>
<span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">build</span>
<span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span> <span class="o">--</span><span class="n">skip</span><span class="o">-</span><span class="n">build</span>
</pre></div>
</div>
<p>In the git repository, the <code class="docutils literal notranslate"><span class="pre">master</span></code> branch corresponds to the latest
release, while the <code class="docutils literal notranslate"><span class="pre">develop</span></code> branch contains code under active development.</p>
<p>Note that installing Pydoop and your MapReduce applications to all cluster
nodes (or to an NFS share) is <em>not</em> required: see <a class="reference internal" href="self_contained.html"><span class="doc">Installation-free Usage</span></a> for
additional info.</p>
</div>
<div class="section" id="troubleshooting">
<h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">“java home not found” error: try setting <code class="docutils literal notranslate"><span class="pre">JAVA_HOME</span></code> in <code class="docutils literal notranslate"><span class="pre">hadoop-env.sh</span></code></p>
</li>
<li><p class="first">“libjvm.so not found” error: try the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">LD_LIBRARY_PATH</span><span class="o">=</span><span class="s2">&quot;$</span><span class="si">{JAVA_HOME}</span><span class="s2">/jre/lib/amd64/server:$</span><span class="si">{LD_LIBRARY_PATH}</span><span class="s2">&quot;</span>
</pre></div>
</div>
</li>
<li><p class="first">non-standard include/lib directories: the setup script looks for
includes and libraries in standard places – read <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> for
details. If some of the requirements are stored in different
locations, you need to add them to the search path. Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">build_ext</span> <span class="o">-</span><span class="n">L</span><span class="o">/</span><span class="n">my</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">path</span> <span class="o">-</span><span class="n">I</span><span class="o">/</span><span class="n">my</span><span class="o">/</span><span class="n">include</span><span class="o">/</span><span class="n">path</span> <span class="o">-</span><span class="n">R</span><span class="o">/</span><span class="n">my</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">path</span>
<span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">build</span>
<span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span> <span class="o">--</span><span class="n">skip</span><span class="o">-</span><span class="n">build</span>
</pre></div>
</div>
<p>Alternatively, you can write a small <code class="docutils literal notranslate"><span class="pre">setup.cfg</span></code> file for distutils:</p>
<div class="highlight-cfg notranslate"><div class="highlight"><pre><span></span><span class="k">[build_ext]</span>
<span class="na">include_dirs</span><span class="o">=</span><span class="s">/my/include/path</span>
<span class="na">library_dirs</span><span class="o">=</span><span class="s">/my/lib/path</span>
<span class="na">rpath</span><span class="o">=</span><span class="s">%(library_dirs)s</span>
</pre></div>
</div>
<p>and then run <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">install</span></code>.</p>
<p>Finally, you can achieve the same result by manipulating the
environment.  This is particularly useful in the case of automatic
download and install with pip:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">CPATH</span><span class="o">=</span><span class="s2">&quot;/my/include/path:$</span><span class="si">{CPATH}</span><span class="s2">&quot;</span>
<span class="n">export</span> <span class="n">LD_LIBRARY_PATH</span><span class="o">=</span><span class="s2">&quot;/my/lib/path:$</span><span class="si">{LD_LIBRARY_PATH}</span><span class="s2">&quot;</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">pydoop</span>
</pre></div>
</div>
</li>
<li><p class="first">Hadoop version issues. The Hadoop version selected at compile time is
automatically detected based on the output of running <code class="docutils literal notranslate"><span class="pre">hadoop</span> <span class="pre">version</span></code>.
If this fails for any reason, you can provide the correct version string
through the <code class="docutils literal notranslate"><span class="pre">HADOOP_VERSION</span></code> environment variable, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">HADOOP_VERSION</span><span class="o">=</span><span class="s2">&quot;2.7.4&quot;</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="testing-your-installation">
<h2>Testing your Installation<a class="headerlink" href="#testing-your-installation" title="Permalink to this headline">¶</a></h2>
<p>After Pydoop has been successfully installed, you might want to run unit
tests and/or examples to verify that everything works fine. Here is a short
list of things that can go wrong and how to fix them. For full details on
running tests and examples, see <code class="docutils literal notranslate"><span class="pre">.travis.yml</span></code>.</p>
<ol class="arabic">
<li><p class="first">make sure that Pydoop is able to detect your Hadoop home and
configuration directories.  If auto-detection fails, try setting
the <code class="docutils literal notranslate"><span class="pre">HADOOP_HOME</span></code> and <code class="docutils literal notranslate"><span class="pre">HADOOP_CONF_DIR</span></code> environment variables
to the appropriate locations;</p>
</li>
<li><p class="first">Make sure all HDFS and YARN daemons are up (see above);</p>
</li>
<li><p class="first">Wait until HDFS exits from safe mode:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>${HADOOP_HOME}/bin/hadoop dfsadmin -safemode wait
</pre></div>
</div>
</li>
<li><p class="first">HDFS tests may fail if your NameNode’s hostname and port are
non-standard. In this case, set the <code class="docutils literal notranslate"><span class="pre">HDFS_HOST</span></code> and <code class="docutils literal notranslate"><span class="pre">HDFS_PORT</span></code>
environment variables accordingly;</p>
</li>
<li><p class="first">Some HDFS tests may fail if not run by the cluster superuser, in
particular <code class="docutils literal notranslate"><span class="pre">capacity</span></code>, <code class="docutils literal notranslate"><span class="pre">chown</span></code> and <code class="docutils literal notranslate"><span class="pre">used</span></code>.  To get superuser
privileges, you can either start the cluster with your own user account or
set the <code class="docutils literal notranslate"><span class="pre">dfs.permissions.superusergroup</span></code> Hadoop property to one of your
unix groups (type <code class="docutils literal notranslate"><span class="pre">groups</span></code> at the command prompt to get the list of
groups for your current user), then restart the HDFS daemons.</p>
</li>
</ol>
</div>
<div class="section" id="using-pydoop-on-amazon-emr">
<span id="emr"></span><h2>Using Pydoop on Amazon EMR<a class="headerlink" href="#using-pydoop-on-amazon-emr" title="Permalink to this headline">¶</a></h2>
<p>You can configure your EMR cluster to automatically install Pydoop on
all nodes via <a class="reference external" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-bootstrap.html">Bootstrap Actions</a>. The
main difficulty is that Pydoop relies on Hadoop being installed and
configured, even at compile time, so the bootstrap script needs to
wait until EMR has finished setting it up:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="nv">PYDOOP_INSTALL_SCRIPT</span><span class="o">=</span><span class="k">$(</span>cat <span class="s">&lt;&lt;EOF</span>
<span class="s">#!/bin/bash</span>
<span class="s">NM_PID=/var/run/hadoop-yarn/yarn-yarn-nodemanager.pid</span>
<span class="s">RM_PID=/var/run/hadoop-yarn/yarn-yarn-resourcemanager.pid</span>
<span class="s">while [ ! -f \${RM_PID} ] &amp;&amp; [ ! -f \${NM_PID} ]; do</span>
<span class="s">  sleep 2</span>
<span class="s">done</span>
<span class="s">export JAVA_HOME=/etc/alternatives/java_sdk</span>
<span class="s">sudo -E pip install pydoop</span>
<span class="s">EOF</span>
<span class="k">)</span>
<span class="nb">echo</span> <span class="s2">&quot;</span><span class="si">${</span><span class="nv">PYDOOP_INSTALL_SCRIPT</span><span class="si">}</span><span class="s2">&quot;</span> <span class="p">|</span> tee -a /tmp/pydoop_install.sh
chmod u+x /tmp/pydoop_install.sh
/tmp/pydoop_install.sh &gt;/tmp/pydoop_install.out <span class="m">2</span>&gt;/tmp/pydoop_install.err <span class="p">&amp;</span>
</pre></div>
</div>
<p>The bootstrap script creates the actual installation script and calls
it; the latter, in turn, waits for either the resource manager or the
node manager to be up (i.e., for YARN to be up whether we are on
the master or on a slave) before installing Pydoop. If you want to use
Python 3, install version 3.6 with yum:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
sudo yum -y install python36-devel python36-pip
sudo alternatives --set python /usr/bin/python3.6
<span class="nv">PYDOOP_INSTALL_SCRIPT</span><span class="o">=</span><span class="k">$(</span>cat &lt;&lt;EOF
...
</pre></div>
</div>
<p>The above instructions have been tested on <code class="docutils literal notranslate"><span class="pre">emr-5.12.0</span></code>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pydoop_script.html" title="Pydoop Script User Guide"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial/mapred_api.html" title="Writing Full-Featured Applications"
             >previous</a> |</li>
	<li><a href="index.html">Home</a>|&nbsp;</li>
	<li><a href="#">Download & Install</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop/issues">Support</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop">Git Repo</a>|&nbsp;</li>
	<li><a href="https://crs4.github.io/pydoop/_pydoop1">Pydoop 1</a></li>
 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2009-2019, CRS4.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.4.
    </div>
  </body>
</html>