
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Easy Hadoop Scripting with Pydoop Script &#8212; Pydoop 2.0a4 documentation</title>
    <link rel="stylesheet" href="../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The HDFS API" href="hdfs_api.html" />
    <link rel="prev" title="Tutorial" href="index.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="hdfs_api.html" title="The HDFS API"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Tutorial"
             accesskey="P">previous</a> |</li>
	<li><a href="../index.html">Home</a>|&nbsp;</li>
	<li><a href="../installation.html">Download & Install</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop/issues">Support</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop">Git Repo</a>|&nbsp;</li>
	<li><a href="https://crs4.github.io/pydoop/_pydoop1">Pydoop 1</a></li>

          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Tutorial</a> &#187;</li> 
      </ul>
    </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/logo.png" alt="Logo"/>
            </a></p>
            <h3><a href="../index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Easy Hadoop Scripting with Pydoop Script</a><ul>
<li><a class="reference internal" href="#writing-and-running-scripts">Writing and Running Scripts</a></li>
<li><a class="reference internal" href="#examples">Examples</a><ul>
<li><a class="reference internal" href="#word-count">Word Count</a></li>
<li><a class="reference internal" href="#map-only-jobs-and-output-separators">Map-only Jobs and Output Separators</a></li>
<li><a class="reference internal" href="#custom-parameters">Custom Parameters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#applicability">Applicability</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="index.html"
                                  title="previous chapter">Tutorial</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="hdfs_api.html"
                                  title="next chapter">The HDFS API</a></p>

					<h4>Get Pydoop</h4>
					<ul>
						<li> <a href="https://pypi.python.org/pypi/pydoop">Download page</a> </li>
						<li> <a href="../installation.html"> Installation Instructions </a> </li>
					</ul>

					<h4>Contributors</h4>
					<p class="topless">
					Pydoop is developed by:
					<a href="http://www.crs4.it">
						<img src="../_static/crs4.png" alt="CRS4" width="200" height="60" />
					</a>
					</p>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="../search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="easy-hadoop-scripting-with-pydoop-script">
<span id="pydoop-script-tutorial"></span><h1>Easy Hadoop Scripting with Pydoop Script<a class="headerlink" href="#easy-hadoop-scripting-with-pydoop-script" title="Permalink to this headline">¶</a></h1>
<p>Pydoop Script is the easiest way to write simple MapReduce programs
for Hadoop.  With Pydoop Script, your code focuses on the core of the
MapReduce model: the mapper and reducer functions.</p>
<div class="section" id="writing-and-running-scripts">
<h2>Writing and Running Scripts<a class="headerlink" href="#writing-and-running-scripts" title="Permalink to this headline">¶</a></h2>
<p>Write a <code class="docutils literal notranslate"><span class="pre">script.py</span></code> Python module that contains the mapper and
reducer functions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mapper</span><span class="p">(</span><span class="n">input_key</span><span class="p">,</span> <span class="n">input_value</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
    <span class="c1"># your computation here</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">intermediate_key</span><span class="p">,</span> <span class="n">intermediate_value</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reducer</span><span class="p">(</span><span class="n">intermediate_key</span><span class="p">,</span> <span class="n">value_iterator</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
    <span class="c1"># your computation here</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">output_key</span><span class="p">,</span> <span class="n">output_value</span><span class="p">)</span>
</pre></div>
</div>
<p>The program can be run as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pydoop</span> <span class="n">script</span> <span class="n">script</span><span class="o">.</span><span class="n">py</span> <span class="n">hdfs_input</span> <span class="n">hdfs_output</span>
</pre></div>
</div>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<p>The following examples show how to use Pydoop Script for common
problems.  More examples can be found in the
<code class="docutils literal notranslate"><span class="pre">examples/pydoop_script</span></code> subdirectory of Pydoop’s source
distribution root.  The <a class="reference internal" href="../pydoop_script.html#pydoop-script-guide"><span class="std std-ref">Pydoop Script Guide</span></a> contains more detailed information on writing
and running programs.</p>
<div class="section" id="word-count">
<span id="id1"></span><h3>Word Count<a class="headerlink" href="#word-count" title="Permalink to this headline">¶</a></h3>
<p>The word count example can be considered as the “hello world” of
MapReduce.  A simple application that counts the occurrence of each
word in a set of text files, it is included in both the original
MapReduce paper <a class="footnote-reference" href="#id3" id="id2">[1]</a> and in the Hadoop documentation as a MapReduce
programming tutorial.  The Pydoop Script implementation requires only
five lines of code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mapper</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">reducer</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">icounts</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">icounts</span><span class="p">))</span>
</pre></div>
</div>
<p>A few more lines allow to set a combiner for local aggregation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">combiner</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">icounts</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;combiner calls&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">reducer</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">icounts</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</pre></div>
</div>
<p>Run the example with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pydoop</span> <span class="n">script</span> <span class="o">-</span><span class="n">c</span> <span class="n">combiner</span> <span class="n">wordcount</span><span class="o">.</span><span class="n">py</span> <span class="n">hdfs_input</span> <span class="n">hdfs_output</span>
</pre></div>
</div>
<p>Note that we need to explicitly set the <code class="docutils literal notranslate"><span class="pre">-c</span></code> flag to activate the
combiner.  By default, no combiner is called.</p>
<p>One thing to remember is that the current Hadoop Pipes architecture
runs the combiner under the hood of the executable run by <code class="docutils literal notranslate"><span class="pre">pipes</span></code>,
so it does not update the combiner counters of the general Hadoop
framework.  Thus, if you run the above script, you’ll get a value of 0
for “Combine input/output records” in the “Map-Reduce Framework”
group, but the “combiner calls” counter should be updated correctly.</p>
</div>
<div class="section" id="map-only-jobs-and-output-separators">
<h3>Map-only Jobs and Output Separators<a class="headerlink" href="#map-only-jobs-and-output-separators" title="Permalink to this headline">¶</a></h3>
<p>Suppose we want to convert all input text to lower case. All we need to do is read each input line, convert it to lower case and emit it (for instance, as the output value). Since there is no aggregation involved, we don’t need a reducer:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mapper</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">record</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</pre></div>
</div>
<p>The only problem with the above code is that, by default, each output key-value pair is written as tab-separated, which would lead to each output line having a leading tab character that’s not found in the original input (note that we’d get a <em>trailing</em> tab if we emitted each record as the output key instead). We can turn off the reduce phase and get an empty separator for output key-value pairs by submitting the job with the following options:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pydoop</span> <span class="n">script</span> <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">reducers</span> <span class="mi">0</span> <span class="o">-</span><span class="n">t</span> <span class="s1">&#39;&#39;</span> <span class="n">lowercase</span><span class="o">.</span><span class="n">py</span> <span class="n">hdfs_input</span> <span class="n">hdfs_output</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-parameters">
<h3>Custom Parameters<a class="headerlink" href="#custom-parameters" title="Permalink to this headline">¶</a></h3>
<p>Suppose we want to select all lines containing a substring to be given at run time (distributed grep). As in the previous example, we can do this with a map-only job (read each input line and emit it if it contains the substring), but we need a way for the user of our application to specify the substring to be matched. This can be done by adding a fourth argument to the mapper function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mapper</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">conf</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">text</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">conf</span><span class="p">[</span><span class="s1">&#39;grep-expression&#39;</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>In this case, Pydoop Script passes the Hadoop job configuration to the <code class="docutils literal notranslate"><span class="pre">mapper</span></code> function as a dictionary via the fourth argument. Moreover, just like Hadoop tools (e.g., <code class="docutils literal notranslate"><span class="pre">hadoop</span> <span class="pre">pipes</span></code>), Pydoop Script allows to set additional configuration parameters via <code class="docutils literal notranslate"><span class="pre">-D</span> <span class="pre">key=value</span></code>. To search for “hello”, for instance, we can run the application as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pydoop</span> <span class="n">script</span> <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">reducers</span> <span class="mi">0</span> <span class="o">-</span><span class="n">t</span> <span class="s1">&#39;&#39;</span> <span class="o">-</span><span class="n">D</span> <span class="n">grep</span><span class="o">-</span><span class="n">expression</span><span class="o">=</span><span class="n">hello</span> \
  <span class="n">grep</span><span class="o">.</span><span class="n">py</span> <span class="n">hdfs_input</span> <span class="n">hdfs_output</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="applicability">
<h2>Applicability<a class="headerlink" href="#applicability" title="Permalink to this headline">¶</a></h2>
<p>Pydoop Script makes it easy to solve simple problems.  It makes it
feasible to write simple (even throw-away) scripts to perform simple
manipulations or analyses on your data, especially if it’s text-based.</p>
<p>If you can specify your algorithm in two simple functions that have no
state or have a simple state that can be stored in module variables,
then you can consider using Pydoop Script.</p>
<p>If you need something more sophisticated, then consider using the
<a class="reference internal" href="mapred_api.html#api-tutorial"><span class="std std-ref">full Pydoop API</span></a>.</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[1]</a></td><td>J. Dean and S. Ghemawat, <em>MapReduce: simplified data processing
on large clusters</em>, in OSDI ‘04: 6th Symposium on Operating
Systems Design and Implementation, 2004</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="hdfs_api.html" title="The HDFS API"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Tutorial"
             >previous</a> |</li>
	<li><a href="../index.html">Home</a>|&nbsp;</li>
	<li><a href="../installation.html">Download & Install</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop/issues">Support</a>|&nbsp;</li>
	<li><a href="https://github.com/crs4/pydoop">Git Repo</a>|&nbsp;</li>
	<li><a href="https://crs4.github.io/pydoop/_pydoop1">Pydoop 1</a></li>

          <li class="nav-item nav-item-1"><a href="index.html" >Tutorial</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2009-2019, CRS4.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.4.
    </div>
  </body>
</html>