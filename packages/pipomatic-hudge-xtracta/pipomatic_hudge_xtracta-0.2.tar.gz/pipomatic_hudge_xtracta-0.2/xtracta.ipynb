{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Union  # From mypy library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import xmltodict  # type: ignore\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from jinja2 import Template\n",
    "from PIL import Image, ImageSequence  # type: ignore\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype, is_numeric_dtype, is_integer_dtype, is_object_dtype, is_string_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows = 100\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "api_key = os.getenv('XTRACTA_API_KEY')\n",
    "database_id = os.getenv('XTRACTA_DATABASE_ID')\n",
    "header_workflow = os.getenv('XTRACTA_HEADER_ID')\n",
    "line_workflow = os.getenv('XTRACTA_LINE_ID')\n",
    "\n",
    "def delete_files(folder):\n",
    "    file_generator = folder.glob('**/*')\n",
    "    file_list = list(file_generator)\n",
    "    for file in file_list:\n",
    "        file.unlink()\n",
    "    return list(file_list)\n",
    "\n",
    "def move_files(samples_folder, file_to_copy, destination_folder):\n",
    "    (destination_folder / file_to_copy).write_bytes((samples_folder / file_to_copy).read_bytes())\n",
    "    return file_to_copy\n",
    "\n",
    "def convert_to_numeric_and_date(df, dayfirst=True):\n",
    "    for column in df.columns:\n",
    "        if is_object_dtype(df[column]) or is_string_dtype(df[column]):\n",
    "            try:\n",
    "                df[column] = pd.to_numeric(df[column], downcast='integer')\n",
    "            except:\n",
    "                try:\n",
    "                    df[column] = df[column].str.replace('$', '')\n",
    "                    df[column] = df[column].str.replace(',', '')\n",
    "                    df[column] = pd.to_numeric(df[column])\n",
    "                except:\n",
    "                    try:\n",
    "                        df[column] = pd.to_datetime(df[column], dayfirst=dayfirst)\n",
    "                    except:\n",
    "                        pass\n",
    "    return df\n",
    "\n",
    "\n",
    "def random_dates(start, end, seed=1, replace=True, number_of_rows=100):\n",
    "    dates = pd.date_range(start, end).to_series()\n",
    "    return dates.sample(number_of_rows, replace=replace, random_state=seed).index\n",
    "    \n",
    "    \n",
    "def dataframe_obfuscator(df, number_of_rows=100):\n",
    "    for column in df.columns:\n",
    "        if is_datetime64_any_dtype(df[column]):\n",
    "            df[column] = random_dates(min(df[column]),max(df[column]), seed=1)\n",
    "        elif is_integer_dtype(df[column]):\n",
    "            df[column] = df[column].fillna(0)\n",
    "            if min(df[column]) < max(df[column]):\n",
    "                df[column] = np.random.randint(min(df[column]),max(df[column]),size=(number_of_rows))\n",
    "            else:\n",
    "                df[column] = min(df[column])\n",
    "        elif is_numeric_dtype(df[column]):\n",
    "            df[column] = df[column].fillna(0)\n",
    "            df[column] = np.random.uniform(min(df[column]),max(df[column]),size=(number_of_rows))\n",
    "        else:\n",
    "            df[column] = 'random text'\n",
    "    return df\n",
    "\n",
    "\n",
    "def obfuscate_csv(data_file, dayfirst=True, number_of_rows=100):\n",
    "    df = pd.read_csv(data_file, nrows=number_of_rows)\n",
    "    df = convert_to_numeric_and_date(df)\n",
    "    df = dataframe_obfuscator(df)\n",
    "    df.to_csv(data_file, header=True, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def obfuscate_excel(data_file, dayfirst=True, number_of_rows=100):\n",
    "    df = pd.read_excel(data_file, nrows=number_of_rows)\n",
    "    display(df.head())\n",
    "    df = convert_to_numeric_and_date(df)\n",
    "    df = dataframe_obfuscator(df)\n",
    "    df.to_excel(data_file, header=True, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "dp = p / 'data'\n",
    "sp = p / 'test_samples'\n",
    "ip = p / 'input'\n",
    "op = p / 'output'\n",
    "jp = p / 'junk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_file = '20190131_invoice.pdf'\n",
    "\n",
    "delete_files(ip)\n",
    "delete_files(op)\n",
    "move_files(sp, test_file, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "df = obfuscate_excel(dp / 'Purchase Order Master Data' / 'SP004.xls')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "df = obfuscate_csv(dp / 'Stock PO Master Data' / 'SP005.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "df = obfuscate_excel(dp / 'Supplier Master Data' / 'SP001.xls')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for interacting with Xtracta's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload file\n",
    "\n",
    "Uploads a PDf or image file for extraction. The classifier field is used if you want to assign a specific classifier to the document rather than letting Xtracta make its own classification decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(api_key, workflow_id, filename, classifier=\"\"):\n",
    "    classifier_xml = (\n",
    "        f'<field_data><field name=\"Classifier\">{classifier}</field></field_data>'\n",
    "    )\n",
    "    upload_url = \"https://api-app.xtracta.com/v1/documents/upload\"\n",
    "    file = {\"userfile\": open(filename, mode=\"rb\")}\n",
    "    data = {\n",
    "        \"api_key\": api_key,\n",
    "        \"workflow_id\": workflow_id,\n",
    "        \"field_data\": classifier_xml,\n",
    "    }\n",
    "    r = requests.post(upload_url, data=data, files=file)\n",
    "    if r.status_code != 200:\n",
    "        print(r.status_code)\n",
    "        return t.text\n",
    "    else:\n",
    "        response = xmltodict.parse(r.text)\n",
    "        return response[\"xml\"][\"document_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_document_id = upload_file(api_key, header_workflow, ip / test_file)\n",
    "test_document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document(api_key: str, document_id: str):\n",
    "    \n",
    "    \"\"\"retrieves the full xml document from Xtracta and converts it to a dict\"\"\"\n",
    "    \n",
    "    documents_url = \"https://api-app.xtracta.com/v1/documents\"\n",
    "    data = {\"api_key\": api_key, \"document_id\": document_id}\n",
    "    try:\n",
    "        r = requests.post(documents_url, data=data)\n",
    "        response = xmltodict.parse(r.text)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return e.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_document = get_document(api_key, test_document_id)\n",
    "test_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xtracta_status(\n",
    "    api_key: str,\n",
    "    workflow_id: str,\n",
    "    status: str,\n",
    "    api_download_status: str = \"active\",\n",
    "    detailed: int = 0,\n",
    "    documents_order: str = \"asc\",\n",
    ") -> list:\n",
    "    \"\"\"Returns a list of all Xtracta documents with a particular status\"\"\"\n",
    "    documents_url = \"https://api-app.xtracta.com/v1/documents\"\n",
    "    data = {\n",
    "        \"api_key\": api_key,\n",
    "        \"workflow_id\": workflow_id,\n",
    "        \"document_status\": status,\n",
    "        \"api_download_status\": api_download_status,\n",
    "        \"items_per_page\": 1000,\n",
    "        \"detailed\": detailed,\n",
    "        \"documents_order\": documents_order,\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(documents_url, data=data)\n",
    "        response = xmltodict.parse(r.text)\n",
    "    except Exception as e:\n",
    "        return [e.__str__]\n",
    "\n",
    "    try:\n",
    "        response_content = response[\"documents_response\"][\"document\"]\n",
    "        if type(response_content) == list:\n",
    "            return response_content\n",
    "        else:\n",
    "            return [response_content]\n",
    "    except Exception as e:\n",
    "        if type(e).__name__ == \"KeyError\":\n",
    "            return [f\"No {status} documents in queue\"]\n",
    "        else:\n",
    "            return [e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_reject_list = get_xtracta_status(api_key, header_workflow, 'reject')\n",
    "test_reject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_documents_to_skip(api_key, header_workflow):\n",
    "    \n",
    "#     \"\"\"You only want to process documents that have data in the document body. \n",
    "#     This function finds documents that are not in this state\"\"\"\n",
    "    \n",
    "#     status_to_skip = ['reject', 'preprocessing', 'output-in-progress']\n",
    "#     items_to_skip = []\n",
    "#     for status in status_to_skip:\n",
    "#         queue = get_xtracta_status(api_key, header_workflow, status)\n",
    "#         for item in queue:\n",
    "#             if item != f'No {status} documents in queue':\n",
    "#                 items_to_skip.append(item['document_id'])\n",
    "#     return items_to_skip      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the output dictionary from Xtracta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(document: Dict[Any, Any]) -> Dict[Any, Any]:\n",
    "    \"\"\"Returns a dictionary with document_id, status and version as top level values \n",
    "    and remaining fields as key value pairs in a header section\"\"\"\n",
    "    output = {}\n",
    "    header_dict = document[\"documents_response\"][\"document\"][\"field_data\"][\"field\"]\n",
    "    header = transform_dict(header_dict)\n",
    "    output[\"document_id\"] = document[\"documents_response\"][\"document\"][\"document_id\"]\n",
    "    output[\"status\"] = document[\"documents_response\"][\"document\"][\"document_status\"]\n",
    "    output[\"version\"] = document[\"documents_response\"][\"document\"][\"@revision\"]\n",
    "    output[\"header\"] = header\n",
    "    return output\n",
    "\n",
    "\n",
    "def transform_dict(start_dict):\n",
    "    end_dict = {}\n",
    "    for item in start_dict:\n",
    "        end_dict[item[\"field_name\"]] = item[\"field_value\"]\n",
    "    return end_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_output = create_output(test_document)\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents_wo_json(folder):\n",
    "    json_files = []\n",
    "    pdfs = []\n",
    "    json_list = list(folder.glob(\"*.json\"))\n",
    "    pdf_list = list(folder.glob(\"*.pdf\"))\n",
    "    for file in json_list:\n",
    "        json_files.append(file.stem)\n",
    "    for pdf in pdf_list:\n",
    "        pdfs.append(pdf.stem)\n",
    "    new_documents = list(set(pdfs) - set(json_files))\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "get_documents_wo_json(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_document_ui(api_key: str, document_id: str) -> str:\n",
    "    \"\"\"Opens the Xtracta UI to fix and train documents\"\"\"\n",
    "    documents_url = \"https://api-app.xtracta.com/v1/documents/ui\"\n",
    "    data = {\n",
    "        \"api_key\": api_key,\n",
    "        \"document_id\": int(document_id),\n",
    "        \"buttons\": \"output,archive\",\n",
    "        \"no_lockout\": 1,\n",
    "        \"expire\": 86400,\n",
    "    }\n",
    "    r = requests.post(documents_url, data=data)\n",
    "    response = xmltodict.parse(r.text)\n",
    "    return response[\"documents_response\"][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_document = get_document(api_key, test_document_id)\n",
    "test_document\n",
    "open_document_ui(api_key, test_document_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_document(\n",
    "    api_key: str, document_id: str, delete: int = 0, api_download_status: str = \"active\"\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Updates document on Xtracta\"\"\"\n",
    "    documents_url = \"https://api-app.xtracta.com/v1/documents/update\"\n",
    "    data = {\n",
    "        \"api_key\": api_key,\n",
    "        \"document_id\": int(document_id),\n",
    "        \"delete\": delete,\n",
    "        \"api_download_status\": api_download_status,\n",
    "    }\n",
    "    r = requests.post(documents_url, data=data)\n",
    "    response = xmltodict.parse(r.text)\n",
    "    return response[\"documents_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "update_document(api_key, test_document_id, api_download_status='active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(document):\n",
    "    lines_dict = document['documents_response']['document']['field_data']['field_set']['row']\n",
    "    lines = []\n",
    "    if len(lines_dict) > 1:\n",
    "        for line_dict in lines_dict:\n",
    "            line = transform_dict(line_dict['field'])\n",
    "            lines.append(line)\n",
    "    else:\n",
    "        line = transform_dict(lines_dict['field'])\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_line_document_id = upload_file(api_key, line_workflow, ip / test_file)\n",
    "test_line_document = get_document(api_key, test_line_document_id)\n",
    "test_lines = get_lines(test_line_document)\n",
    "test_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_simple(filename, output):\n",
    "    with open(f\"{filename}\", \"w\") as f:\n",
    "        f.write(json.dumps(output, indent=4))\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "test_json_string = 'invoice_simple.json'\n",
    "test_json_file = write_json_simple(ip / test_json_string, test_output)\n",
    "test_json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(old_name, new_name, dp, output):\n",
    "    print(old_name, new_name, dp)\n",
    "    duplicate_name = dp / new_name.name\n",
    "    if new_name.exists():\n",
    "        with open(f\"{duplicate_name}\", \"w\") as f:\n",
    "            f.write(json.dumps(output, indent=4))\n",
    "    else:\n",
    "        with open(f\"{new_name}\", \"w\") as f:\n",
    "            f.write(json.dumps(output, indent=4))\n",
    "    if new_name.exists():\n",
    "        old_name.unlink()\n",
    "        return new_name\n",
    "    else:\n",
    "        return \"File not saved!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "write_json(test_json_file, op / test_json_file.name, dp, test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build output once in output status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_out_output(filename, document, output):\n",
    "    output['stem'] = filename.stem\n",
    "    output['new_filename'] = f\"{output['header']['supplier_id']}-{output['header']['invoice_number']}\"\n",
    "    output['header']['emaildate'] = get_email_date(filename)\n",
    "    output['document_url'] = document['documents_response']['document']['document_url']\n",
    "    output['image_urls'] = get_image_urls(document['documents_response']['document']['image_url'])\n",
    "    return output\n",
    "\n",
    "def get_email_date(filename):\n",
    "    year = filename.stem[:4]\n",
    "    month = filename.stem[4:6]\n",
    "    day = filename.stem[6:8]\n",
    "    return f\"{year}-{month}-{day}\"\n",
    "\n",
    "def get_image_urls(image_urls):\n",
    "    if type(image_urls) != list:\n",
    "        image_urls = [image_urls]\n",
    "    return image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "full_test_output = build_out_output(ip / 'invoice.pdf', test_document, test_output)\n",
    "full_test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull company name and location from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_company_location(output):\n",
    "    company_extract = re.compile(r'.*\\[<<(.*)>>\\].*')\n",
    "    company_location = company_extract.match(output['header']['email_subject'])[1]\n",
    "    try:\n",
    "        output['company'], output['location'] = company_location.split('-')\n",
    "    except:\n",
    "        output['company'] = company_location\n",
    "        output['location'] = 'NA'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "full_test_output['header']['email_subject'] = '234 [<<ABC-123>>] Here is a subject'\n",
    "full_test_output = add_company_location(full_test_output)\n",
    "full_test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving files in the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "def move_to_output(op, filename, dp, output):\n",
    "    new_name = (op / output['new_filename']).with_suffix('.json')\n",
    "    save_tif(new_name, output['image_urls'])\n",
    "    write_json(filename, new_name, dp, output)\n",
    "    print()\n",
    "    print(f'Document {filename.stem} moved to output')\n",
    "    return True\n",
    "\n",
    "def move_to_junk(jp, filename, output):\n",
    "    new_name = jp / filename\n",
    "    write_json(filename, new_name, jp, output)\n",
    "    print()\n",
    "    print(f'Document {filename.stem} moved to deleted')\n",
    "    return True\n",
    "\n",
    "def create_tif_image(image_urls):\n",
    "    images = []\n",
    "    for i, url in enumerate(image_urls):\n",
    "        r = requests.get(url, stream=True)\n",
    "        if i == 0:\n",
    "            im = Image.open(r.raw)\n",
    "        else:\n",
    "            images.append(Image.open(r.raw))\n",
    "    return im, images\n",
    "\n",
    "def save_tif(new_filename, image_urls):\n",
    "    new_name = op / new_filename.with_suffix('.tif')\n",
    "    im, images = create_tif_image(image_urls)\n",
    "    im.save(f'{new_name}', save_all=True, append_images=images)\n",
    "    return im, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "move_files(sp, test_file, ip)\n",
    "move_to_output(jp, ip / test_file, dp, full_test_output)\n",
    "move_files(sp, test_file, ip)\n",
    "move_to_junk(op, ip / test_file, full_test_output)\n",
    "move_files(sp, test_file, ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting XML for upload into Xtracta's database\n",
    "\n",
    "Take a list of dicts and format it for uploading to Xtracta's database API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_database_data(api_key, database_id, out, refresh):\n",
    "    documents_url = 'https://api-app.xtracta.com/v1/databases/data_add'\n",
    "    data = {'api_key': api_key, 'database_id': int(database_id), 'data': out, 'refresh': refresh}\n",
    "    r = requests.post(documents_url, data=data)\n",
    "    response = xmltodict.parse(r.text)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xml_data(supplier_data_dict):\n",
    "    xml_rows = []\n",
    "    for row in supplier_data_dict:\n",
    "        po = {'column': [{'@id': '55261', '#text': f\"{row['po_number']}\"}, \n",
    "                         {'@id': '55264', '#text': f\"{row['supplier_number']}\"},\n",
    "                         {'@id': '60223', '#text': f\"{row['line_number']}\"},\n",
    "                         {'@id': '58133', '#text': f\"{row['abn']}\"},\n",
    "                         {'@id': '58134', '#text': f\"{row['bsb']}\"},\n",
    "                         {'@id': '58135', '#text': f\"{row['bank_account']}\"},\n",
    "                         {'@id': '58242', '#text': f\"{row['supplier_name']}\"}]}\n",
    "        xml_rows.append(po)\n",
    "    xml_data = {'xml': {'row': xml_rows}}\n",
    "    return xmltodict.unparse(xml_data, pretty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build HTML file for handling rejections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_section(data, html_template):\n",
    "    template = Template(html_template)\n",
    "    html = template.render(data=data)\n",
    "    return html\n",
    "\n",
    "\n",
    "reject_queue_html_template = \"\"\"\n",
    "    <div class=\"column is-full\">\n",
    "        <p><strong>Total number of rejects in queue: {{data.reject_count}}</strong></p>\n",
    "    </div>\n",
    "    <div class=\"column is-full\">  \n",
    "        <h2><strong>{{data.output.header.supplier}}</strong></h2>\n",
    "        <p><strong>Invoice number:</strong> {{data.output.header.invoice_number}}</p>\n",
    "    </div>\n",
    "    <div class=\"column is-two-fifths\">\n",
    "    <section class=\"section has-text-right\">\n",
    "        <p><strong>Net:</strong> {{\"$%.2f\"|format(data.output.header.net_total|float)}}</p>\n",
    "        <p><strong>GST:</strong> {{\"$%.2f\"|format(data.output.header.gst_total|float)}}</p>\n",
    "        <p><strong>Total:</strong> {{\"$%.2f\"|format(data.output.header.gross_total|float)}}</p>\n",
    "    </section>\n",
    "    <section class=\"section\">\n",
    "        <table class=\"table\">\n",
    "        <thead><tr><th>Field</th><th>Message</th></tr></thead>\n",
    "        <tbody>\n",
    "        {% for message in data.messages %}\n",
    "        <tr>\n",
    "            <th>{{message.field}}</th>\n",
    "            <td>{{message.message}}</td>\n",
    "        </tr>\n",
    "        {% endfor %}\n",
    "        </tbody>\n",
    "        </table>\n",
    "    </section>\n",
    "    </div>\n",
    "    <div class=\"column is-three-fifths has-text-centered\">\n",
    "        <p><a href=\"{{data.review_link}}\" target=\"_blank\">Review invoice</a></p>\n",
    "        <p><img src=\"{{data.invoice_image}}\" alt=\"Invoice Image\" width=\"250\"></p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_reject_html(api_key, workflow_id, status, html_template):\n",
    "    queue = get_xtracta_status(api_key, workflow_id, status)\n",
    "    reject_count = len(queue)\n",
    "    document_id = queue[0][\"document_id\"]\n",
    "    reasons = queue[0][\"rejection\"][\"reason\"]\n",
    "    messages = get_reject_info(api_key, document_id, reasons)\n",
    "    document = get_document(api_key, document_id)\n",
    "    image_url = document[\"documents_response\"][\"document\"][\"image_url\"][0]\n",
    "    output = create_output(document)\n",
    "    review_link = open_document_ui(api_key, document_id)\n",
    "    data = {\n",
    "        \"output\": output,\n",
    "        \"reject_count\": reject_count,\n",
    "        \"review_link\": review_link,\n",
    "        \"invoice_image\": image_url,\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    html = create_html_section(data=data, html_template=html_template)\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reject_info(api_key, document_id, reasons):\n",
    "    messages = []\n",
    "    document = get_document(api_key, document_id)\n",
    "    field_ids = get_field_ids(document)\n",
    "    if type(reasons) != list:\n",
    "        field_id = reasons[\"linked_field\"][\"field_id\"]\n",
    "        message = reasons[\"message\"]\n",
    "        messages.append({\"field\": field_ids[field_id], \"message\": message})\n",
    "    else:\n",
    "        for sub_item in reasons:\n",
    "            field_id = sub_item[\"linked_field\"][\"field_id\"]\n",
    "            message = sub_item[\"message\"]\n",
    "            messages.append({\"field\": field_ids[field_id], \"message\": message})\n",
    "    return messages\n",
    "\n",
    "\n",
    "def get_field_ids(document):\n",
    "    field_ids = {}\n",
    "    fields = document[\"documents_response\"][\"document\"][\"field_data\"][\"field\"]\n",
    "    for field in fields:\n",
    "        field_ids[field[\"field_id\"]] = field[\"field_name\"]\n",
    "    return field_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build code\n",
    "\n",
    "The remaining cells load the code to PIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook xtracta.ipynb to python\n",
      "[NbConvertApp] Writing 18564 bytes to xtracta.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pipomatic_hudge_xtracta.py'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!jupyter nbconvert \\\n",
    "    --TagRemovePreprocessor.enabled=True \\\n",
    "    --TagRemovePreprocessor.remove_cell_tags=\"['build']\" \\\n",
    "    --TemplateExporter.exclude_output=True \\\n",
    "    --to python \"xtracta.ipynb\"\n",
    "\n",
    "first_line = \"\"\"'Xtracta package'\n",
    "\n",
    "__version__ = '0.1'\n",
    "\n",
    "\"\"\"\n",
    "script_file = Path.cwd() / 'xtracta.py'\n",
    "script = script_file.read_text()\n",
    "script_file.write_text(first_line + script)\n",
    "username = script_file.parent.parent.name\n",
    "system_name = script_file.parent.name\n",
    "standardised_script_name = f'pipomatic_{username}_{system_name}.py'\n",
    "script_file.replace(script_file.parent / standardised_script_name)\n",
    "standardised_script_name\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reformatted pipomatic_hudge_xtracta.py\n",
      "All done! \\u2728 \\U0001f370 \\u2728\n",
      "1 file reformatted.\n"
     ]
    }
   ],
   "source": [
    "!black \"pipomatic_hudge_xtracta.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "build"
    ]
   },
   "outputs": [],
   "source": [
    "# !flit publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
