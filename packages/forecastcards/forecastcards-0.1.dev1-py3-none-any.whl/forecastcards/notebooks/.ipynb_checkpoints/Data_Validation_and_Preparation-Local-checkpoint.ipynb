{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5S3Mi75wYV0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/elizabeth/Documents/urbanlabs/NCHRP 08-110/working/forecastcards\n",
      "Requirement already satisfied, skipping upgrade: pandas==0.22 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from forecastcards==0.1.0.dev0) (0.22.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from forecastcards==0.1.0.dev0) (2.20.1)\n",
      "Requirement already satisfied, skipping upgrade: goodtables in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from forecastcards==0.1.0.dev0) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: tableschema in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from forecastcards==0.1.0.dev0) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: graphviz in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from forecastcards==0.1.0.dev0) (0.10.1)\n",
      "Requirement already satisfied, skipping upgrade: statsmodels in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from forecastcards==0.1.0.dev0) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from forecastcards==0.1.0.dev0) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from pandas==0.22->forecastcards==0.1.0.dev0) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from pandas==0.22->forecastcards==0.1.0.dev0) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from pandas==0.22->forecastcards==0.1.0.dev0) (2018.7)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from requests->forecastcards==0.1.0.dev0) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from requests->forecastcards==0.1.0.dev0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from requests->forecastcards==0.1.0.dev0) (2018.10.15)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from requests->forecastcards==0.1.0.dev0) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: simpleeval<2.0,>=0.9 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from goodtables->forecastcards==0.1.0.dev0) (0.9.8)\n",
      "Requirement already satisfied, skipping upgrade: six<2.0,>=1.9 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from goodtables->forecastcards==0.1.0.dev0) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: click-default-group in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from goodtables->forecastcards==0.1.0.dev0) (1.2)\n",
      "Requirement already satisfied, skipping upgrade: click<7.0,>=6.6 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from goodtables->forecastcards==0.1.0.dev0) (6.7)\n",
      "Requirement already satisfied, skipping upgrade: datapackage<2.0,>=1.2 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from goodtables->forecastcards==0.1.0.dev0) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: statistics<2.0,>=1.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from goodtables->forecastcards==0.1.0.dev0) (1.0.3.5)\n",
      "Requirement already satisfied, skipping upgrade: tabulator<2.0,>=1.3 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from goodtables->forecastcards==0.1.0.dev0) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: isodate<2.0,>=0.5.4 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tableschema->forecastcards==0.1.0.dev0) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema<3.0,>=2.5 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tableschema->forecastcards==0.1.0.dev0) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: rfc3986<2.0,>=1.1.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tableschema->forecastcards==0.1.0.dev0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: unicodecsv<2.0,>=0.14 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tableschema->forecastcards==0.1.0.dev0) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: patsy in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from statsmodels->forecastcards==0.1.0.dev0) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-console in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter->forecastcards==0.1.0.dev0) (6.0.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter->forecastcards==0.1.0.dev0) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter->forecastcards==0.1.0.dev0) (7.4.2)\n",
      "Requirement already satisfied, skipping upgrade: qtconsole in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter->forecastcards==0.1.0.dev0) (4.4.3)\n",
      "Requirement already satisfied, skipping upgrade: notebook in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter->forecastcards==0.1.0.dev0) (5.7.2)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter->forecastcards==0.1.0.dev0) (5.4.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonpointer<2.0,>=1.10 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from datapackage<2.0,>=1.2->goodtables->forecastcards==0.1.0.dev0) (1.14)\n",
      "Requirement already satisfied, skipping upgrade: cchardet<3.0,>=1.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from datapackage<2.0,>=1.2->goodtables->forecastcards==0.1.0.dev0) (2.1.4)\n",
      "Requirement already satisfied, skipping upgrade: docutils>=0.3 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from statistics<2.0,>=1.0->goodtables->forecastcards==0.1.0.dev0) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: linear-tsv<2.0,>=1.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: openpyxl<2.5,>=2.4 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (2.4.11)\n",
      "Requirement already satisfied, skipping upgrade: jsonlines<2.0,>=1.1 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: sqlalchemy<2.0,>=0.9.6 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (1.2.14)\n",
      "Requirement already satisfied, skipping upgrade: xlrd<2.0,>=1.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: ijson<3.0,>=2.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter-console->jupyter->forecastcards==0.1.0.dev0) (5.2.3)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.1.0,>=2.0.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter-console->jupyter->forecastcards==0.1.0.dev0) (2.0.7)\n",
      "Requirement already satisfied, skipping upgrade: ipython in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter-console->jupyter->forecastcards==0.1.0.dev0) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jupyter-console->jupyter->forecastcards==0.1.0.dev0) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipykernel->jupyter->forecastcards==0.1.0.dev0) (4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipykernel->jupyter->forecastcards==0.1.0.dev0) (5.1.1)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.4.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipywidgets->jupyter->forecastcards==0.1.0.dev0) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipywidgets->jupyter->forecastcards==0.1.0.dev0) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from qtconsole->jupyter->forecastcards==0.1.0.dev0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from qtconsole->jupyter->forecastcards==0.1.0.dev0) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from notebook->jupyter->forecastcards==0.1.0.dev0) (2.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: Send2Trash in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from notebook->jupyter->forecastcards==0.1.0.dev0) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from notebook->jupyter->forecastcards==0.1.0.dev0) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from notebook->jupyter->forecastcards==0.1.0.dev0) (17.1.2)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from notebook->jupyter->forecastcards==0.1.0.dev0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from nbconvert->jupyter->forecastcards==0.1.0.dev0) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: mistune>=0.8.1 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from nbconvert->jupyter->forecastcards==0.1.0.dev0) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from nbconvert->jupyter->forecastcards==0.1.0.dev0) (0.2.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from nbconvert->jupyter->forecastcards==0.1.0.dev0) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from nbconvert->jupyter->forecastcards==0.1.0.dev0) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from nbconvert->jupyter->forecastcards==0.1.0.dev0) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: jdcal in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from openpyxl<2.5,>=2.4->tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (1.4)\n",
      "Requirement already satisfied, skipping upgrade: et-xmlfile in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from openpyxl<2.5,>=2.4->tabulator<2.0,>=1.3->goodtables->forecastcards==0.1.0.dev0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (4.6.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (40.6.2)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (0.13.1)\n",
      "Requirement already satisfied, skipping upgrade: appnope; sys_platform == \"darwin\" in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jinja2->notebook->jupyter->forecastcards==0.1.0.dev0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess; os_name != \"nt\" in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from terminado>=0.8.1->notebook->jupyter->forecastcards==0.1.0.dev0) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from bleach->nbconvert->jupyter->forecastcards==0.1.0.dev0) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.3.0 in /anaconda/envs/forecastcards/lib/python3.6/site-packages (from jedi>=0.10->ipython->jupyter-console->jupyter->forecastcards==0.1.0.dev0) (0.3.1)\n",
      "Building wheels for collected packages: forecastcards\n",
      "  Running setup.py bdist_wheel for forecastcards ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/60/xd2kny110pxfz3ln611jq7hm0000gn/T/pip-ephem-wheel-cache-2_z9g1mg/wheels/d0/d4/f9/2a525455b03f69bc95fcbc11f800fcc010800425cdf26ca30d\n",
      "Successfully built forecastcards\n",
      "Installing collected packages: forecastcards\n",
      "Successfully installed forecastcards-0.1.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forecastcards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YlHI1siswpNL"
   },
   "source": [
    "# Data Validation and Preparation\n",
    "\n",
    "1. Find and map where the data is\n",
    "2. Validate data conforms to schema\n",
    "3. Combine data\n",
    "4. Clean and format data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWaDWr4CxGgI"
   },
   "source": [
    "## 1 - Map the Cards\n",
    "\n",
    "Finds all the relevant cards and assigns them a type in order to compare to the data schema.\n",
    "\n",
    "Returns a dictionary of card locations by card type.\n",
    "\n",
    "**`map_cards`**`(  \n",
    "    repo_loc = default_repo_api,   \n",
    "    subdirs  = default_subdirs \n",
    "  ):`\n",
    "\n",
    "\n",
    "  - **`repo_loc`** - API tree URL for data to be used\n",
    "  - **`subdirs`**  - list of subdirs to search through\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hm2WFKh9woAD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.github.com/repos/e-lo/forecastcards/git/trees/master?recursive=1\n",
      "https://api.github.com/repos/e-lo/forecastcards/git/trees/66b3e4fac72da8d179fa2cbd4a06870624b321ba?recursive=1\n",
      "https://raw.githubusercontent.com/e-lo/forecastcards/master/\n",
      "https://raw.githubusercontent.com/e-lo/forecastcards/master/\n",
      "opening https://raw.githubusercontent.com/e-lo/forecastcards/master/forecastcards/examples/ecdot-rx123-yellowbrickroadhov/project.csv\n",
      "adding rx123  - valid\n"
     ]
    }
   ],
   "source": [
    "schema_locs = { 'poi'         : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/poi-schema.json\",\n",
    "                \"scenario\"    : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/scenario-schema.json\",\n",
    "                \"project\"     : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/project-schema.json\",\n",
    "                \"observations\": \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/observations-schema.json\",\n",
    "                \"forecast\"    : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/forecast-schema.json\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "data_reports = forecastcards.validate_cards(card_locs,schema_locs)\n",
    "\n",
    "default_data_loc = os.path.join('forecastcards','examples')\n",
    "projects         = []\n",
    "exclude_projects = []\n",
    "\n",
    "#should add cards to map, not initiate\n",
    "# map = map_cards()\n",
    "#         add_cards()\n",
    "#            sniff, add method\n",
    "\n",
    "import glob, csv\n",
    "from goodtables import validate\n",
    "import requests,csv\n",
    "\n",
    "def get_csv_from_url(url):\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(url)\n",
    "\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        return cr\n",
    "\n",
    "def raw_github_url(username, repository, branch='master'):\n",
    "    gh = \"https://raw.githubusercontent.com/\"+str(username)+\"/\"+str(repository)+\"/\"+str(branch)+\"/\"\n",
    "    return gh\n",
    "\n",
    "def api_github_url(username, repository, branch='master'):\n",
    "    gh = \"https://api.github.com/repos/\"+str(username)+\"/\"+str(repository)+\"/git/trees/\"+str(branch)+\"?recursive=1\"\n",
    "    return gh\n",
    "\n",
    "\n",
    "class Cardset:\n",
    "    def __init__(self,\n",
    "                 data_loc ='../forecastcards/examples', \n",
    "                 select_projects = [], \n",
    "                 exclude_projects = [], \n",
    "                 schemas ={},\n",
    "                 schema_locs = schema_locs,\n",
    "                ):\n",
    "        \n",
    "        self.card_locs = {'poi'         : [],\n",
    "                          'scenario'    : [],\n",
    "                          'observations': [],\n",
    "                          'forecast'    : [],\n",
    "                          'project'     : []}\n",
    "                            \n",
    "        self.data_locs = []\n",
    "        self.schema_locs = schema_locs # dict by card type of urls to JSON files or schema instances\n",
    "        \n",
    "        # list of all projects\n",
    "        self.projects = []\n",
    "        \n",
    "        # validation status\n",
    "        self.validated_projects   = []\n",
    "        self.unvalidated_projects = []\n",
    "        self.invalid_projects     = []\n",
    "        \n",
    "        # valid project requires following valid components\n",
    "        self.validity_requires    = ['project','poi','observations','scenario','forecast']\n",
    "        \n",
    "        # add initial projects\n",
    "        self.add_projects(data_loc, select_projects=select_projects, exclude_projects=exclude_projects)\n",
    "    \n",
    "    def validate_project(self, p_card_locs, schema_locs={}, validity_requires = []):\n",
    "        \n",
    "        if not schema_locs:\n",
    "            schema_locs = self.schemas_locs\n",
    "            \n",
    "        if not validity_requires: \n",
    "            validity_requires = self.validity_requires\n",
    "            \n",
    "        ## todo validate against local schemas\n",
    "        valid        = True\n",
    "        fail_reports = []\n",
    "        \n",
    "        for card_type, locs in p_card_locs.items():\n",
    "            #print (\"validating\",card_type, locs)\n",
    "        \n",
    "            ##todo add other validation checks here\n",
    "            for card in locs:\n",
    "                report = validate(card ,schema=requests.get(schema_locs[card_type]).json())\n",
    "                if not report['valid']:\n",
    "                    if card_type in validity_requires:\n",
    "                        valid = False\n",
    "                    print (\"Validation Error:\", card)\n",
    "                    fail_reports.append(report)\n",
    "                    \n",
    "        return valid, fail_reports\n",
    "    \n",
    "    def check_project_id(self, project_id, select_projects=[], exclude_projects=[]):\n",
    "        '''\n",
    "        :returns: True if project should be added; False if it shouldn't\n",
    "        '''\n",
    "        # check to see if project should be added\n",
    "        if project_id in self.projects:\n",
    "            print(\"Excluding\", project_id, \" already in cardset\")\n",
    "            return False\n",
    "        elif projects and project_id not in projects:\n",
    "            print(\"Excluding\", project_id, \" because it isn't in project list\")\n",
    "            return False\n",
    "        elif exclude_projects and project_id in exclude_projects:\n",
    "            print(\"Excluding\", project_id, \" because it is in the exclusion list\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def add_github_projects(self, data_loc, select_projects=[], exclude_projects=[]):\n",
    "        '''\n",
    "        :data_loc: is expecting a dictionary with username, repository, branch\n",
    "        \n",
    "        This is messy right now b/c we have to loop though several times. \n",
    "        1. to find project IDs and their directories that we want to import\n",
    "        2. to find all the files in those directories\n",
    "        3. to validate the project once we have all those files together\n",
    "        \n",
    "        It would be a lot easier if we were able to take the directory names as the project id or similar.\n",
    "        '''\n",
    "        import requests\n",
    "        import re\n",
    "        \n",
    "        repo_loc = api_github_url(\n",
    "            username = data_loc['username'], \n",
    "            repository = data_loc['repository'], \n",
    "            branch = data_loc['branch'])\n",
    "        \n",
    "        repo_raw = raw_github_url(\n",
    "            username = data_loc['username'], \n",
    "            repository = data_loc['repository'], \n",
    "            branch = data_loc['branch']) \n",
    "        \n",
    "        \n",
    "        subdirs  = ['forecastcards/examples']\n",
    "        projdirs_to_import = {}\n",
    "        cards_by_project = {}\n",
    "        \n",
    "        r = requests.get(repo_loc)\n",
    "        rj = r.json()\n",
    "        #if verbose: print(rj)\n",
    "        card_locs = {\n",
    "               \"poi\": [],\n",
    "               \"scenario\": [],\n",
    "               \"project\": [],\n",
    "               \"observations\": [],\n",
    "               \"forecast\": [],\n",
    "        }\n",
    "        \n",
    "        # First loop through is to find all the projects that we want to import\n",
    "        # We need to get their project ids as well as the folders they live in\n",
    "        for file in rj['tree']:\n",
    "            #print (file['path'])\n",
    "            \n",
    "            # don't look at things that aren't files\n",
    "            if file['type']!='blob': continue\n",
    "\n",
    "            # split path into a list\n",
    "            path_list = file['path'].split(\"/\")\n",
    "\n",
    "            # don't look in wrong subdirs\n",
    "            if subdirs and not any(s in file['path'] for s in subdirs): continue\n",
    "           \n",
    "            # find project*.csv and get project id\n",
    "            if path_list[-1][-4:].lower()==\".csv\" and path_list[-1][0:7].lower() == \"project\":\n",
    "                print(\"opening\",urljoin(repo_raw,file['path']))\n",
    "                # open project*csv to see if we have a good project id\n",
    "                \n",
    "                proj_csv = list(get_csv_from_url(urljoin(repo_raw,file['path'])))\n",
    "                #print(proj_csv)\n",
    "            \n",
    "                assert(proj_csv[0][0] == 'project_id')\n",
    "                project_id   = proj_csv[1][0].strip().lower()\n",
    "                \n",
    "                project_path = os.path.dirname(file['path'])\n",
    "                #print(project_path)\n",
    "            \n",
    "                # check to see if we should be adding this project\n",
    "                if not self.check_project_id(project_id, select_projects=select_projects, exclude_projects=exclude_projects):\n",
    "                    continue                                       \n",
    "                \n",
    "                # add this directory to the list to import, and to overall project lists\n",
    "                projdirs_to_import[project_path] = project_id\n",
    "                cards_by_project[project_id] = {\n",
    "                    'project' : [urljoin(repo_raw,file['path'])],\n",
    "                    'scenario': [],\n",
    "                    'forecast': [],\n",
    "                    'observations' :[],\n",
    "                    'poi':[],\n",
    "                }\n",
    "                self.projects.append(project_id)\n",
    "                self.unvalidated_projects.append(project_id)\n",
    "                \n",
    "                \n",
    "        # second loop back through files to find the ones in the right project directory\n",
    "        for file in rj['tree']:\n",
    "\n",
    "            #make sure you should be importing this file\n",
    "            if not any( pdirs in file['path'] for pdirs in projdirs_to_import.keys() ):\n",
    "                continue\n",
    "\n",
    "            ## don't look at things that aren't files\n",
    "            if file['type']!='blob': continue\n",
    "\n",
    "            # split path into a list\n",
    "            path_list = file['path'].split(\"/\")\n",
    "\n",
    "            if path_list[-1][-4:].lower()!=\".csv\": continue\n",
    "\n",
    "            if path_list[-1][0:8].lower()==\"scenario\":\n",
    "                project_path = os.path.dirname(file['path'])\n",
    "                project_id = projdirs_to_import[project_path]\n",
    "                cards_by_project[project_id]['scenario'].append(urljoin(repo_raw,file['path']))\n",
    "                #print(\"adding scenario:\",file['path'])\n",
    "            if path_list[-1][0:8].lower()==\"forecast\":\n",
    "                project_path = os.path.dirname(os.path.dirname(file['path']))\n",
    "                project_id = projdirs_to_import[project_path]\n",
    "                cards_by_project[project_id]['forecast'].append(urljoin(repo_raw,file['path']))\n",
    "                #print(\"adding forecast:\",file['path'])\n",
    "            if path_list[-1][0:12].lower()==\"observations\":\n",
    "                project_path = os.path.dirname(os.path.dirname(file['path']))\n",
    "                project_id = projdirs_to_import[project_path]\n",
    "                cards_by_project[project_id]['observations'].append(urljoin(repo_raw,file['path']))\n",
    "                #print(\"adding observation:\",file['path'])\n",
    "            if path_list[-1][0:3].lower()==\"poi\":\n",
    "                project_path = os.path.dirname(file['path'])\n",
    "                project_id = projdirs_to_import[project_path]\n",
    "                cards_by_project[project_id]['poi'].append(urljoin(repo_raw,file['path']))\n",
    "                #print(\"adding poi:\",file['path'])\n",
    "                \n",
    "        #Third loop is through the cards_by_project, which need to be validated all together\n",
    "        failed_validation_reports = []\n",
    "        for project_id, cards in cards_by_project.items():\n",
    "            p_valid, fail_reports = self.validate_project(cards,self.schema_locs)\n",
    "            \n",
    "            if p_valid: \n",
    "                self.validated_projects.append(project_id)\n",
    "                self.unvalidated_projects.remove(project_id)\n",
    "                print(\"adding\",project_id,\" - valid\")\n",
    "                for k,v in self.card_locs.items():\n",
    "                    v += cards[k]\n",
    "                else: \n",
    "                    self.invalid_projects.append(project_id)\n",
    "            \n",
    "            failed_validation_reports.append(fail_reports)\n",
    "        return failed_validation_reports\n",
    "    \n",
    "    def add_local_projects(self, data_loc, select_projects=[], exclude_projects=[]):\n",
    "        \n",
    "        #find projects by searching for the project csv file\n",
    "        project_loc = os.path.join(data_loc,'**/project*.csv')\n",
    "        \n",
    "        failed_validation_reports = []\n",
    "        \n",
    "        ##todo make more windows safe\n",
    "        for filepath in glob.iglob(project_loc, recursive=True):\n",
    "            with open(filepath, 'r') as f:\n",
    "                proj_csv = list(csv.reader(f))\n",
    "            \n",
    "            assert(proj_csv[0][0] == 'project_id')\n",
    "            project_id   = proj_csv[1][0].strip().lower()\n",
    "\n",
    "            project_path = os.path.dirname(filepath)\n",
    "            \n",
    "            #check to see if we should be adding this project\n",
    "            if not self.check_project_id(project_id, select_projects=select_projects, exclude_projects=exclude_projects):\n",
    "                continue\n",
    "                \n",
    "            self.projects.append(project_id)\n",
    "            self.unvalidated_projects.append(project_id)\n",
    "                \n",
    "            p_card_locs = {'poi'         : glob.glob(os.path.join(project_path,'poi*.csv'),recursive=True),\n",
    "                           'scenario'    : glob.glob(os.path.join(project_path,'scenario*.csv'),recursive=True),\n",
    "                           'observations': glob.glob(os.path.join(project_path,'**/observations*.csv'),recursive=True),\n",
    "                           'forecast'    : glob.glob(os.path.join(project_path,'**/forecast*.csv'),recursive=True),\n",
    "                           'project'     : [filepath]}\n",
    "            \n",
    "            p_valid, fail_reports = self.validate_project(p_card_locs,self.schema_locs)\n",
    "            \n",
    "            if p_valid: \n",
    "                self.validated_projects.append(project_id)\n",
    "                self.unvalidated_projects.remove(project_id)\n",
    "                print(\"adding\",project_id,\" - valid\")\n",
    "                for k,v in self.card_locs.items():\n",
    "                    v += p_card_locs[k]\n",
    "            else: \n",
    "                self.invalid_projects.append(project_id)\n",
    "            \n",
    "            failed_validation_reports.append(fail_reports)\n",
    "    \n",
    "        return failed_validation_reports\n",
    "                \n",
    "    \n",
    "    def add_projects(self, data_loc, select_projects=[], exclude_projects=[]):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.data_locs.append(data_loc)\n",
    "        \n",
    "        if type(data_loc) is dict:\n",
    "            reports = self.add_github_projects(data_loc,select_projects=select_projects, exclude_projects=exclude_projects)\n",
    "        \n",
    "        else:\n",
    "            reports = self.add_local_projects(data_loc,select_projects=select_projects, exclude_projects=exclude_projects)\n",
    "        \n",
    "                \n",
    "card_map = Cardset({'username':'e-lo','repository':'forecastcards','branch':'master'})\n",
    "#card_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x11778ac88>\n"
     ]
    }
   ],
   "source": [
    "u = 'https://raw.githubusercontent.com/e-lo/forecastcards/master/forecastcards/examples/ecdot-rx123-yellowbrickroadhov/project.csv'\n",
    "\n",
    "with requests.Session() as s:\n",
    "    \n",
    "    download = s.get(u)\n",
    "\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    c = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "    cr = list(c)\n",
    "    print(c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znDdRbDAxPdP"
   },
   "source": [
    "## 2 - Validate Forecast Card Data\n",
    "\n",
    "Uses [Frictionless Good Tables](https://github.com/frictionlessdata/goodtables-py) to validate that the data matches the schemas.\n",
    "\n",
    "Returns a dictionary of reports by card type.\n",
    "\n",
    "**`validate_cards`**`(  \n",
    "    card_locs,\n",
    "    schemas_loc \n",
    "   ):`\n",
    "\n",
    "\n",
    "  - **`card_locs`** - dictionary of `card type`: list of files\n",
    "  - **`schemas_loc`** - dictionary of `card type` : schema locations\n",
    "\n",
    "**TIP: ** If data doesn't validate, try to resolve with the GUI at  https://try.goodtables.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jn2U1t5Lym4z"
   },
   "outputs": [],
   "source": [
    "schema_locs = { 'poi'         : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/poi-schema.json\",\n",
    "                \"scenario\"    : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/scenario-schema.json\",\n",
    "                \"project\"     : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/project-schema.json\",\n",
    "                \"observations\": \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/observations-schema.json\",\n",
    "                \"forecast\"    : \"https://raw.github.com/e-lo/forecast-cards/master/spec/en/forecast-schema.json\",\n",
    "}\n",
    "\n",
    "data_reports = forecastcards.validate_cards(card_locs,schema_locs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDfD4CAjyP8V"
   },
   "outputs": [],
   "source": [
    "data_reports['poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N35s48TM0fsg"
   },
   "source": [
    "## 3 - Combine Data\n",
    "\n",
    "Returns a dictionary of reports by card type.\n",
    "\n",
    "**`validate_cards`**`(  \n",
    "    card_locs \n",
    "    schemas_loc \n",
    "   ):`\n",
    "\n",
    "\n",
    "  - **`card_locs`** - dictionary of `card type`: list of files\n",
    "  - **`schemas_loc`** - dictionary of `card type` : schema locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LuUXrw320f5h"
   },
   "outputs": [],
   "source": [
    "all_df = forecastcards.combine_data(card_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h--fqzwO0mpD"
   },
   "outputs": [],
   "source": [
    "all_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUn3cT5q2yhk"
   },
   "source": [
    "## 4 - Clean and Recode\n",
    "\n",
    "- Fix missing values\n",
    "- Code categorical variables\n",
    "- Scale for estimation\n",
    "\n",
    "Note that this entire process can be exceuted by calling `default_data_clean(df)`\n",
    "\n",
    "### Fix Missing Values\n",
    "\n",
    "Returns a dataframe that has some missing data recoded to 'missing' and some records dropped because they didn't have minimum values.\n",
    "\n",
    "**`fix_missing_values`**`(  \n",
    "    dataframe\n",
    "    recode_na_vars = default_recode_na_vars\n",
    "    no_na_vars     = default_no_na_vars\n",
    "   ):`\n",
    "\n",
    "\n",
    "  - **`recode_na_vars`** - list of variables to recode NA to \"missing\"\n",
    "  - **`no_na_vars`** - list of variables where having an NA isn't acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jx5kx1XI21J8"
   },
   "outputs": [],
   "source": [
    "recode_na_vars = ['forecast_system_type', 'area_type', 'forecaster_type', 'state', 'agency', 'functional_class','facility_type','project_type']\n",
    "no_na_vars     = ['scenario_date','forecast_creation_date','forecast_value','obs_value']\n",
    "\n",
    "select_df = forecastcards.fix_missing_values(all_df,\n",
    "                                             recode_na_vars=recode_na_vars,\n",
    "                                             no_na_vars=no_na_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6ekOBXe3Pxx"
   },
   "source": [
    "### Create Categorical Variables\n",
    "\n",
    "1. Add categorical variables for project size (cutoff: 30k), scenario decade and forecast decade.\n",
    "\n",
    "   Returns a dataframe.\n",
    "\n",
    "   **`create_default_categorical_vars`**`(  \n",
    "    dataframe\n",
    "   )`\n",
    "   \n",
    "2. Recodes categorical variables to dummy variables.\n",
    "\n",
    "    Returns a dataframe.\n",
    "\n",
    "    **`categorical_to_dummy`**`(  \n",
    "    dataframe\n",
    "    categorical_cols_list=default_categorical_cols,\n",
    "    required_vars = default_required_vars\n",
    "   ):`\n",
    "   \n",
    " \n",
    " - **`categorical_cols_list`** - list of columns that will be recoded  \n",
    " - **`required_vars`** - list of variables that will be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6xCThU43eXM"
   },
   "outputs": [],
   "source": [
    "select_df = forecastcards.create_default_categorical_vars(select_df)\n",
    "estimate_df = forecastcards.categorical_to_dummy(select_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-ZPskdT17mP"
   },
   "outputs": [],
   "source": [
    "estimate_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBwsBfsr3gUD"
   },
   "source": [
    "### Scale \n",
    "\n",
    "Returns a dataframe that has the dummy variables scaled to the forecast value so that the estimation isn't biased.\n",
    "\n",
    "**`scale_dummies_by_forecast`**`(  \n",
    "    dataframe\n",
    "    no_scale_cols=default_no_scale_cols\n",
    "   ):`\n",
    "\n",
    "\n",
    "  - **`no_scale_cols`** - list of variables that won't be scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IWuIkH43fo9"
   },
   "outputs": [],
   "source": [
    "scaled_df = forecastcards.scale_dummies_by_forecast_value(estimate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sugovd462g_P"
   },
   "source": [
    "# Dataset ready for Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4r9eEzo72kFG"
   },
   "outputs": [],
   "source": [
    "scaled_df.describe()\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LftuXV7j2lpG"
   },
   "outputs": [],
   "source": [
    "estimate_df.plot.scatter(y='forecast_value',\n",
    "                         x='obs_value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P5C0nDlC627"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Validation and Preparation",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
