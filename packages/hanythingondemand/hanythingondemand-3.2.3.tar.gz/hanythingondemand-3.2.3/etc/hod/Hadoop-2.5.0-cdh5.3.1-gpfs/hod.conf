#-*- cfg -*-
# vim: ft=cfg
[Meta]
version=1

[Config]
modules=Hadoop/2.5.0-cdh5.3.1
master_env=HADOOP_HOME,EBROOTHADOOP,JAVA_HOME
services=resourcemanager.conf,nodemanager.conf,screen.conf
config_writer=hod.config.writer.hadoop_xml
# Point the workdir to a path on the parallel file system using the command
# line named argument: --config-workdir=...
#workdir=
directories=$localworkdir/dfs/name,$localworkdir/dfs/data

[core-site.xml]
fs.defaultFS=gpfs:///
fs.gpfs.impl=org.apache.hadoop.fs.gpfs.GeneralParallelFileSystem
fs.AbstractFileSystem.gpfs.impl=org.apache.hadoop.fs.gpfs.GeneralParallelFs
# Change the following (gpfs.mount.dir) to the mount directory on gpfs.
gpfs.mount.dir=$worksir
gpfs.supergroup=
dfs.blocksize=268435456

[mapred-site.xml]
mapreduce.framework.name=yarn                                                         
mapreduce.map.memory.mb=4096
mapreduce.reduce.memory.mb=8192
mapreduce.map.java.opts=-Xmx3072m
mapreduce.reduce.java.opts=-Xmx6144m
mapreduce.job.working.dir=$localworkdir
yarn.app.mapreduce.am.staging-dir=$workdir/$hostname/hadoop-staging 

[yarn-site.xml]
yarn.nodemanager.local-dirs=$localworkdir/$hostname
yarn.resourcemanager.hostname=$masterdataname
yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler

[log4j.properties]
log4j.logger.org.apache.hadoop=INFO
log4j.logger.org.apache.hadoop.yarn=INFO
# GPFS audit logger
log4j.additivity.org.apache.hadoop.fs.gpfs.GeneralParallelFileSystem.audit=false
log4j.logger.org.apache.hadoop.fs.gpfs.GeneralParallelFileSystem.audit=INFO,NullAppender
